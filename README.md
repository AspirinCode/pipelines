# Piplelines.

The project experiments with ways to generate data processing piplelines. 
The aim is to generate some re-usable building blocks that can be piped 
together into more functional pipelines. Their prime initial use is as executors
for the Squonk Computational Notebook (http://squonk.it) though it is expected
that they will have uses in other environments.

As well as being executable directly they can also be executed in Docker
containers (separately or as a single pipeline). Additionally they can be 
executed using Nextflow (http://nextflow.io) to allow running large jobs 
on HPC-like environments.

Currently it has some python scripts using RDKit (http://rdkit.org) to provide 
basic cheminformatics and comp chem functionality, though other tools will 
be coming soon, including some from the Java ecosystem.
See [here](src/python/rdkit/README.md) for more info on the RDKit components.

Note: this is experimental, everything is subject to change, and 
there are no guarantees that anything works!
That said, if you are interested let me know, and join the fun.

The code is licensed under the Apache 2.0 license.

## General principles

### Modularity

Each component should be small but useful. Try to split complex tasks into 
reusable steps. Think how the same steps could be used in other workflows.
Allow parts of one component to be used in another component where appropriate
but avoid over use. For example see the use of functions in rdkit/conformers.py 
to generate conformers in o3dAlign.py 

### Consistency

Consistent approach to how components function, regarding:

1. Use as simple command line tools that can be piped together
1. Input and outputs either as files of using STDIN and STDOUT
1. Any info/logging written to STDERR to keep STDOUT free for output
1. Consistent approach to command line arguments across components

Generally use consistent coding styles e.g. PEP8 for Python.

## Input and output formats

We aim to provide consistent input and output formats to allow results to be 
passed between different implementations. Currently all implementations handle 
chemical structures so SD file would typically be used as the lowest common
denominator interchange format, but implementations should also try to support 
Squonk's JSON based Dataset formats, which potentially allow richer representations
and can be used to describe data other than chemical structures. 
The utils.py module provides helper methods to handle IO. 

### Thin output
 
In addition implementations are encouraged to support "thin" output formats
where this is appropriate. A "thin" representation is a minimal representation 
containing only what is new or changed, and can significantly reduce the bandwith
used and avoid the need for the consumer to interpret values it does not 
need to understand. It is not always appropriate to support thin format output 
(e.g. when the structure is changed by the process).

In the case of SDF thin format involves using an empty molecule for the molecule 
block and all properties that were present in the input or were generated by the 
process (the empty molecule is used so that the SDF syntax remains valid). 

In the case of Squonk JSON output the thin output would be of type BasicObject 
(e.g. containing no structure information) and include all properties that 
were present in the input or were generated by the process. 

Implicit in this is that some identifier (usually a SD file property, or 
the JSON UUID property) that is present in the input is included in the output so 
that the full results can be "reassembled" by the consumer of the output. 
The input would typically only contain additional information that is required 
for execution of the process e.g. the structure.

For consistency implementations should try to honor these command line 
switches relating to input and output:

-i and --input: For specifying the location of the single input. If not specified 
then STDIN should be used. File names ending with .gz should be interpreted as 
gzipped files. Input on STDIN should not be gzipped. 

-if and --informat: For specifying the input format where it cannot be inferred 
from the file name (e.g. when using STDIN). Values would be sdf or json.

-o and --output: For specifying the base name of the ouputs (there could be multiple
output files each using the same base name but with a different file extension.
If not specified then STDOUT should be used. Output file names ending with 
.gz should be compressed using gzip. Output on STDOUT would not be gzipped. 

-of and --outformat: For specifying the output format where it cannot be inferred 
from the file name (e.g. when using STDOUT). Values would be sdf or json.
 
--meta: Write additional metadata and metrics (mostly relevant to Squonk's 
JSON format). Default is not to write.

--thin: Write output in thin format (only present where this makes sense).
Default is not to use thin format.

## Contact

Any questions contact: 

Tim Dudgeon
tdudgeon@informaticsmatters.com
